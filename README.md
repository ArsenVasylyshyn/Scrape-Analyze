# Job Scraper & Analyzer

A structured Python project that scrapes job vacancies for **Data Engineers** from job websites (like **dow.ua**), extracts **technologies** using keyword matching, and stores everything in a **SQLite** database. It supports **CSV export**, **database viewing**, and **tech analysis** via charts and tables.

---

## ğŸ› ï¸ Technologies

![Python](https://img.shields.io/badge/Python-3.10+-blue?logo=python&logoColor=white)
![BeautifulSoup](https://img.shields.io/badge/BeautifulSoup4-Web%20Scraping-yellow?logo=beautifulsoup&logoColor=black)
![lxml](https://img.shields.io/badge/lxml-Parser-green?logo=xml&logoColor=white)
![Requests](https://img.shields.io/badge/Requests-HTTP%20Client-lightgrey?logo=python&logoColor=black)
![Selenium](https://img.shields.io/badge/Selenium-automation-43B02A?logo=selenium&logoColor=white)
![WebDriverManager](https://img.shields.io/badge/WebDriver_Manager-Installers-blueviolet?logo=selenium&logoColor=white)
![Tabulate](https://img.shields.io/badge/Tabulate-CLI%20Tables-orange?logo=python&logoColor=white)
![SQLite](https://img.shields.io/badge/SQLite-embedded-lightgrey?logo=sqlite&logoColor=blue)
![Matplotlib](https://img.shields.io/badge/Matplotlib-visualization-orange)
![Pandas](https://img.shields.io/badge/Pandas-data%20analysis-150458?logo=pandas)

## ğŸ”¥ Features

- ğŸ” Scrape job vacancies using Selenium & BeautifulSoup
- ğŸ§  Extract technologies from descriptions using predefined keyword dictionary
- ğŸ—ƒï¸ Store vacancies, technologies & relations in a normalized SQLite DB
- ğŸ“¤ Export results to CSV
- ğŸ“ˆ Analyze top technologies using Matplotlib + Pandas
- ğŸ–¥ï¸ View job records and tech keywords in a tabulated format

## ğŸ“¦ Project Structure

| File/Folder            | Description                                     |
| ---------------------- | ----------------------------------------------- |
| `main.py`              | ğŸ¯ Main entry point for the scraper             |
| `Makefile`             | âš™ï¸ Useful CLI commands (run, view, export)      |
| `requirements.txt`     | ğŸ“¦ Python dependencies                          |
| `README.md`            | ğŸ“˜ Project documentation                        |
| `data/`                | ğŸ—‚ï¸ Output folder for database and CSV files     |
| â”œâ”€â”€ `top_techs.png`    | ğŸ“ˆ Chart top technologies                       |
| â”œâ”€â”€ `vacancies.db`     | ğŸ§± SQLite database file                         |
| â””â”€â”€ `vacancies.csv`    | ğŸ“„ CSV output with parsed job data              |
| `src/`                 | ğŸ§  Source code                                  |
| â”œâ”€â”€ `scraper.py`       | ğŸ•·ï¸ Scraping logic with Selenium & BeautifulSoup |
| â”œâ”€â”€ `sqlite_db.py`     | ğŸ—ƒï¸ SQLite database interactions                 |
| â”œâ”€â”€ `export.py`        | ğŸ“¤ CSV export logic                             |
| â”œâ”€â”€ `show_db.py`       | ğŸ‘€ Show DB contents                             |
| â”œâ”€â”€ `tech_keywords.py` | ğŸ§  Dictionary of tech stack terms               |
| â””â”€â”€ `analysis.py`      | ğŸ“ˆ Analysis + chart of top N technologies       |

---

## ğŸ§© Example Result Parsing (SQLite tables Vacancies, Technologies)

<pre>
ğŸ“‹ Vacancies:
+-----+---------------------------------------------+------------+-----------+
| ID  | Title                                       | Company    | Link      |
+-----+---------------------------------------------+------------+-----------+             
| 1   | Senior Backend Engineer (Data Processing)   | Shelf      | [Link]    |
| 2   | Data Engineer (JustDone)                    | Boosters   | [Link]    |
| 3   | R&D CV/ML Engineer (Drones â€” Miltech)       | A19Lab.com | [Link]    |
| 4   | ML/DL Engineer (Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ñ–Ğ¹Ğ½Ñ– Ğ¼Ğ¾Ğ´ĞµĞ»Ñ–)      | ROZETKA    | [Link]    |
| 5   | Sr. DevOps Engineer / Data Architect        | Datagrok   | [Link]    |
</pre>

<pre>
ğŸ§ª Technologies:
+----+--------------------+
| ID | Technology         |
+----+--------------------+
| 1  | AWS                |
| 2  | Azure              |
| 3  | Elastic            |
| 4  | ETL                |
| 5  | Great Expectations |
</pre>

## ğŸ“ˆ Example result analysis

Top technologies:

#### Tables

<pre>
+----+------------------------+
| â„–  | Technology | Frequency |
+----+------------+-----------+
| 1  | python     |    113    |
| 2  | sql        |     94    |
| 3  | etl        |     91    |
| 4  | aws        |     77    |
| 5  | azure      |     64    |
</pre>

#### Chart

![Top technologies](data/top_techs.png)

## ğŸš€ Run Project: Makefile Commands

| Command        | Description                                                            |
| -------------- | ---------------------------------------------------------------------- |
| `make run`     | Runs the main scraper script to collect job listings.                  |
| `make initdb`  | Initializes the SQLite database by creating necessary tables.          |
| `make showdb`  | Displays the contents of the database (vacancies and technologies).    |
| `make analyze` | Performs analysis on the data and shows top technologies with a chart. |
| `make clean`   | Removes the database and CSV files to clean the workspace.             |

### Usage Examples

- Run the scraper and save data:

  ```bash
  make run
  ```

---

## ğŸ‘¤ About the Author

This project was developed by **Arsen Vasylyshyn**, a dedicated Data Engineer specializing in data processing and automation.

---

## ğŸ”— GitHub Author Repository

You can find other project repositories and related resources on GitHub:

[![GitHub](https://img.shields.io/badge/GitHub-%2312100E.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/ArsenVasylyshyn)
